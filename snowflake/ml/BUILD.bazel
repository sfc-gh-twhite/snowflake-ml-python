load("//bazel:py_rules.bzl", "py_library", "snowml_wheel")
load(":version.bzl", "VERSION")

package(default_visibility = ["//visibility:public"])

_TENSORFLOW_REQUIRES = ["tensorflow>=2.9,<3"]

_PYTORCH_REQUIRES = ["torchdata>=0.4,<1"]

_LIGHTGBM_REQUIRES = ["lightgbm==3.3.5"]

_ALL_REQUIRES = _TENSORFLOW_REQUIRES + _PYTORCH_REQUIRES + _LIGHTGBM_REQUIRES

genrule(
    name = "generate_version",
    outs = ["version.py"],
    cmd = "echo 'VERSION=\"" + VERSION + "\"'> $@",
)

py_library(
    name = "version",
    srcs = ["version.py"],
    deps = [],
)

snowml_wheel(
    name = "wheel",
    compatible_with_snowpark = False,
    development_status = "PrPr",
    extra_requires = {
        "tensorflow": _TENSORFLOW_REQUIRES,
        "pytorch": _PYTORCH_REQUIRES,
        "lightgbm": _LIGHTGBM_REQUIRES,
        "all": _ALL_REQUIRES,
    },
    # TODO(zhuo): consider adding a check to make sure what's listed
    # here is a subset that is compatible with what is specified in conda-env.yml.
    requires = [
        "absl-py>=0.15,<2",
        "anyio>=3.5.0,<4",
        "cloudpickle", # Version range is specified by snowpark. We are implicitly depending on it.
        "fsspec[http]>=2022.11,<=2023.1",
        "numpy>=1.23,<2",
        "packaging>=20.9,<24",
        "pandas>=1.0.0,<2",  # Limit since 2.x is not available in Snowflake Anaconda Channel yet.
        "pyyaml>=6.0,<7",
        "scikit-learn>=1.2.1,<2",
        "scipy>=1.9,<2",
        "snowflake-connector-python[pandas]",
        "snowflake-snowpark-python>=1.4.0,<2",
        "sqlparse>=0.4,<1",
        "typing-extensions>=4.1.0,<5",
        "xgboost>=1.7.3,<2",
    ],
    version = VERSION,
    deps = [
        "//snowflake/ml/metrics:metrics_pkg",
        "//snowflake/ml/sklearn/preprocessing:preprocessing_pkg",
        "//snowflake/ml/utils:utils_pkg",
        "//snowflake/ml/fileset:fileset_pkg",
        "//snowflake/ml/registry:model_registry_pkg",
        # Auotgen packages
        "//snowflake/ml/sklearn/linear_model:sklearn_linear_model_pkg",
        "//snowflake/ml/sklearn/ensemble:sklearn_ensemble_pkg",
        "//snowflake/ml/sklearn/svm:sklearn_svm_pkg",
        "//snowflake/ml/sklearn/neural_network:sklearn_neural_network_pkg",
        "//snowflake/ml/sklearn/tree:sklearn_tree_pkg",
        "//snowflake/ml/sklearn/calibration:sklearn_calibration_pkg",
        "//snowflake/ml/sklearn/cluster:sklearn_cluster_pkg",
        "//snowflake/ml/sklearn/compose:sklearn_compose_pkg",
        "//snowflake/ml/sklearn/covariance:sklearn_covariance_pkg",
        "//snowflake/ml/sklearn/decomposition:sklearn_decomposition_pkg",
        "//snowflake/ml/sklearn/discriminant_analysis:sklearn_discriminant_analysis_pkg",
        "//snowflake/ml/sklearn/feature_selection:sklearn_feature_selection_pkg",
        "//snowflake/ml/sklearn/gaussian_process:sklearn_gaussian_process_pkg",
        "//snowflake/ml/sklearn/impute:sklearn_impute_pkg",
        "//snowflake/ml/sklearn/isotonic:sklearn_isotonic_pkg",
        "//snowflake/ml/sklearn/kernel_approximation:sklearn_kernel_approximation_pkg",
        "//snowflake/ml/sklearn/kernel_ridge:sklearn_kernel_ridge_pkg",
        "//snowflake/ml/sklearn/manifold:sklearn_manifold_pkg",
        "//snowflake/ml/sklearn/mixture:sklearn_mixture_pkg",
        "//snowflake/ml/sklearn/model_selection:sklearn_model_selection_pkg",
        "//snowflake/ml/sklearn/multiclass:sklearn_multiclass_pkg",
        "//snowflake/ml/sklearn/multioutput:sklearn_multioutput_pkg",
        "//snowflake/ml/sklearn/naive_bayes:sklearn_naive_bayes_pkg",
        "//snowflake/ml/sklearn/neighbors:sklearn_neighbors_pkg",
        "//snowflake/ml/sklearn/semi_supervised:sklearn_semi_supervised_pkg",
        "//snowflake/ml/xgboost:xgboost_pkg",
        "//snowflake/ml/lightgbm:lightgbm_pkg",
    ],
)
