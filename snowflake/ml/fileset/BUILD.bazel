load("//bazel:py_rules.bzl", "py_library", "py_test", "snowml_wheel")
load("@rules_python//python:packaging.bzl", "py_package")

package(default_visibility = ["//visibility:public"])

py_library(
    name = "stage_fs",
    srcs = ["stage_fs.py"],
    deps = [
        ":fileset_errors",
        "//snowflake/ml/utils:telemetry",
    ],
)

py_test(
    name = "stage_fs_test",
    srcs = ["stage_fs_test.py"],
    compatible_with_snowpark = False,
    deps = [
        ":stage_fs",
        "//snowflake/ml/test_utils:mock_data_frame",
        "//snowflake/ml/test_utils:mock_session",
    ],
)

py_library(
    name = "sfcfs",
    srcs = ["sfcfs.py"],
    deps = [
        ":fileset_errors",
        ":stage_fs",
        "//snowflake/ml/utils:identifier",
        "//snowflake/ml/utils:telemetry",
    ],
)

py_test(
    name = "sfcfs_test",
    srcs = ["sfcfs_test.py"],
    deps = [
        ":sfcfs",
    ],
)

py_package(
    name = "fileset_pkg",
    packages = ["snowflake.ml"],
    deps = [
        ":fileset",
        ":sfcfs",
        ":stage_fs",
    ],
)

py_library(
    name = "fileset",
    srcs = ["fileset.py"],
    compatible_with_snowpark = False,
    deps = [
        ":fileset_errors",
        ":sfcfs",
        ":tf_dataset",
        ":torch_datapipe",
        "//snowflake/ml/utils:import_utils",
        "//snowflake/ml/utils:telemetry",
    ],
)

py_test(
    name = "fileset_test",
    srcs = ["fileset_test.py"],
    deps = [
        ":fileset",
    ],
)

py_library(
    name = "parquet_parser",
    srcs = ["parquet_parser.py"],
)

py_test(
    name = "parquet_parser_test",
    srcs = ["parquet_parser_test.py"],
    deps = [
        ":parquet_parser",
        ":parquet_test_util",
    ],
)

py_library(
    name = "torch_datapipe",
    srcs = ["torch_datapipe.py"],
    compatible_with_snowpark = False,
    deps = [":parquet_parser"],
)

py_test(
    name = "torch_datapipe_test",
    srcs = ["torch_datapipe_test.py"],
    compatible_with_snowpark = False,
    deps = [
        ":parquet_test_util",
        ":torch_datapipe",
    ],
)

py_library(
    name = "tf_dataset",
    srcs = ["tf_dataset.py"],
    deps = [":parquet_parser"],
)

py_test(
    name = "tf_dataset_test",
    srcs = ["tf_dataset_test.py"],
    compatible_with_snowpark = False,
    deps = [
        ":parquet_test_util",
        ":tf_dataset",
    ],
)

py_library(
    name = "fileset_errors",
    srcs = ["fileset_errors.py"],
)

py_library(
    name = "parquet_test_util",
    testonly = True,
    srcs = ["parquet_test_util.py"],
)

_TENSORFLOW_REQUIRES = ["tensorflow>=2.9,<3"]

_PYTORCH_REQUIRES = ["torchdata>=0.4,<1"]

_ALL_REQUIRES = _TENSORFLOW_REQUIRES + _PYTORCH_REQUIRES

snowml_wheel(
    name = "fileset_wheel",
    compatible_with_snowpark = False,
    development_status = "PrPr",
    extra_requires = {
        "tensorflow": _TENSORFLOW_REQUIRES,
        "pytorch": _PYTORCH_REQUIRES,
        "all": _ALL_REQUIRES,
    },
    # TODO(zhuo): consider adding a check to make sure what's listed
    # here is a subset that is compatible with what is specified in conda-env.yml.
    requires = [
        "absl-py>=0.15,<2",
        "fsspec[http]>=2022.11,<=2023.1",
        "numpy>=1.23,<1.24",
        "pyyaml>=6.0,<7",
        "snowflake-connector-python[pandas]",
        "snowflake-snowpark-python>=1.0.0,<=1.3",
    ],
    version = "0.2.2",
    deps = [
        "//snowflake/ml/fileset:fileset_pkg",
    ],
)
